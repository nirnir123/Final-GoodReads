{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99c169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1a10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://www.goodreads.com/list/show/35857.The_Most_Popular_Fantasy_on_Goodreads?page=\",\n",
    "        \"https://www.goodreads.com/list/show/46916.Popular_Fantasy_on_Goodreads_with_between_50000_and_99999_ratings?page=\",\n",
    "        \"https://www.goodreads.com/list/show/74893.Popular_Fantasy_on_Goodreads_with_between_25000_and_49999_ratings?page=\",\n",
    "        \"https://www.goodreads.com/list/show/76860.Popular_Fantasy_on_Goodreads_with_between_10000_and_24999_ratings?page=\"\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af28023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.goodreads.com/list/show/35857.The_Most_Popular_Fantasy_on_Goodreads?page=\n",
      "https://www.goodreads.com/list/show/46916.Popular_Fantasy_on_Goodreads_with_between_50000_and_99999_ratings?page=\n",
      "https://www.goodreads.com/list/show/74893.Popular_Fantasy_on_Goodreads_with_between_25000_and_49999_ratings?page=\n",
      "https://www.goodreads.com/list/show/76860.Popular_Fantasy_on_Goodreads_with_between_10000_and_24999_ratings?page=\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81b1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0d1f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of pages\n",
      "end of pages\n",
      "end of pages\n",
      "end of pages\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path='chromedriver')\n",
    "\n",
    "#driver.get(\"https://www.goodreads.com/list/show/76860.Popular_Fantasy_on_Goodreads_with_between_10000_and_24999_ratings?page=20\")\n",
    "\n",
    "#soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "#next_button = soup.find_all('a',attrs={'class':'next_page'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "book_url=[]\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "#degl=1\n",
    "degl=0\n",
    "\n",
    "\n",
    "i = 1\n",
    "\n",
    "\n",
    "for ur in urls:\n",
    "    degl=1\n",
    "    i=1\n",
    "    while(degl):\n",
    "\n",
    "        crafted_url = ur + str(i)\n",
    "        driver.get(crafted_url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        for link in soup.find_all(\"a\", class_=\"bookTitle\"):\n",
    "            book_url.append(\"https://www.goodreads.com/\"+link.get('href'))\n",
    "\n",
    "\n",
    "\n",
    "        next_page_disabled = soup.find_all('span',attrs={'class':'next_page disabled'})\n",
    "\n",
    "        if (len(next_page_disabled) >= 1):\n",
    "            degl=0\n",
    "            print(\"end of pages\")\n",
    "        else:\n",
    "            i = i + 1\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "d ={'book_url':book_url}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24abf6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)\n",
    "df.drop_duplicates(subset=['book_url'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303f459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4064\n"
     ]
    }
   ],
   "source": [
    "book=book_url\n",
    "print(len(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92786b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(0,1):\n",
    "#     book.append(book_url[i])\n",
    "\n",
    "# print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "004aa76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "book_name=[]\n",
    "book_series=[]\n",
    "book_series_number=[]\n",
    "authorName=[]\n",
    "description=[]\n",
    "pages=[]\n",
    "\n",
    "\n",
    "rating=[]\n",
    "rating_Count=[]\n",
    "reviews_Count=[]\n",
    "\n",
    "\n",
    "ISBN=[]\n",
    "ISBN13=[]\n",
    "\n",
    "\n",
    "\n",
    "published_year=[]\n",
    "published_month=[]\n",
    "first_published_year=[]\n",
    "first_published_month=[]\n",
    "\n",
    "\n",
    "Rating5=[]\n",
    "Rating4=[]\n",
    "Rating3=[]\n",
    "Rating2=[]\n",
    "Rating1=[]\n",
    "\n",
    "Rating5_Percent=[]\n",
    "Rating4_Percent=[]\n",
    "Rating3_Percent=[]\n",
    "Rating2_Percent=[]\n",
    "Rating1_Percent=[]\n",
    "\n",
    "people_liked=[]\n",
    "\n",
    "#Edition_Language=[]\n",
    "\n",
    "\n",
    "\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "month_dict = { \"january\" : 1 ,\n",
    "               \"february\" : 2 ,\n",
    "               \"march\" : 3 ,\n",
    "               \"april\" : 4 ,\n",
    "               \"may\" : 5 ,\n",
    "               \"june\" : 6 ,\n",
    "               \"july\" : 7 ,\n",
    "               \"august\" : 8 ,\n",
    "               \"september\" : 9 ,\n",
    "               \"october\" : 10 ,\n",
    "               \"november\" : 11 ,\n",
    "               \"december\" : 12  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29d8757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='chromedriver')\n",
    "\n",
    "book_40=0\n",
    "iiii=0\n",
    "\n",
    "for bo in book:\n",
    "    \n",
    "    book_40=book_40+1\n",
    "    \n",
    "    if (book_40==40):\n",
    "        book_40=0\n",
    "        iiii=iiii+1\n",
    "        df2= pd.DataFrame({'book_name':book_name,'book_series':book_series,'book_series_number':book_series_number,\n",
    "                  'authorName':authorName,'description':description,'pages':pages,'rating':rating,'rating_Count':rating_Count,\n",
    "                  'reviews_Count':reviews_Count,'ISBN':ISBN,'ISBN13':ISBN13,'published_year':published_year,\n",
    "                  'published_month':published_month,'first_published_year':first_published_year,\n",
    "                  'first_published_month':first_published_month,'Rating5':Rating5,'Rating4':Rating4,'Rating3':Rating3,\n",
    "                  'Rating2':Rating2,'Rating1':Rating1,'Rating5_Percent':Rating5_Percent,'Rating4_Percent':Rating4_Percent,\n",
    "                  'Rating3_Percent':Rating3_Percent,'Rating2_Percent':Rating2_Percent,'Rating1_Percent':Rating1_Percent,\n",
    "                  'people_liked':people_liked})\n",
    "        \n",
    "        \n",
    "        name=\"books_40_\"+str(iiii)+\".csv\"\n",
    "        df2.to_csv(name,index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    #crafted_url = i\n",
    "    driver.get(bo)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    time.sleep(2)\n",
    "##############\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        book_name0=soup.find(\"h1\").get_text()\n",
    "        book_name.append(book_name0)\n",
    "    except:\n",
    "        book_name.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        book_series_no=soup.find('h2',attrs={'id':'bookSeries'}).find('a').get_text() \n",
    "        book_series0 = re.sub(r'[^a-zA-Z ]', '', book_series_no)\n",
    "        book_series_number0 = re.sub(r'[^0-9]', '', book_series_no)\n",
    "        book_series.append(book_series0)\n",
    "        book_series_number.append(book_series_number0)\n",
    "        \n",
    "    except:\n",
    "        book_series.append(np.nan)\n",
    "        book_series_number.append(np.nan)\n",
    "    try:\n",
    "        authorName0=soup.find('a',attrs={'class':'authorName'}).get_text()                \n",
    "        authorName.append(authorName0)\n",
    "\n",
    "    except:\n",
    "        authorName.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        description0=soup.find('div',attrs={'id':'description'}).get_text()\n",
    "        description.append(description0)\n",
    "        \n",
    "    except:\n",
    "        description.append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        details=soup.find('div',attrs={'id':'details'}).find('span',attrs={'itemprop':'numberOfPages'}).get_text()\n",
    "        numberOfPages0 = re.sub(r'[^0-9 ]', '', details)\n",
    "        pages.append(numberOfPages0)\n",
    "    except:        \n",
    "        pages.append(np.nan)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "####    \n",
    "       \n",
    "    \n",
    "    try:#6\n",
    "        rating__rating_Count__reviews_Count = driver.find_element(By.ID, \"bookMeta\").text\n",
    "        r_rC_rc = re.sub(r'[^0-9. ]', '', rating__rating_Count__reviews_Count)\n",
    "        r_rC_rc = r_rC_rc.split()\n",
    "        rating.append(r_rC_rc[0])\n",
    "        rating_Count.append(r_rC_rc[1])\n",
    "        reviews_Count.append(r_rC_rc[2])\n",
    "        \n",
    "    except:\n",
    "        rating.append(np.nan)\n",
    "        rating_Count.append(np.nan)\n",
    "        reviews_Count.append(np.nan)   \n",
    "\n",
    "    \n",
    "####\n",
    "\n",
    "    try:#5\n",
    "        ISBN_all=soup.find_all('div',attrs={'class':'infoBoxRowItem'})[1].get_text()\n",
    "        ISBN_all2 = re.sub(r'[^0-9. ]', '', ISBN_all)\n",
    "        ISBN_all2=ISBN_all2.split()\n",
    "        ISBN.append(ISBN_all2[0])\n",
    "        if(len(ISBN_all2)>=3):\n",
    "            ISBN13.append(ISBN_all2[2])\n",
    "        else:\n",
    "            ISBN13.append(np.nan)\n",
    "    except:\n",
    "        ISBN.append(np.nan)\n",
    "        ISBN13.append(np.nan)\n",
    "    \n",
    "\n",
    "  \n",
    "    \n",
    "####\n",
    "    \n",
    "    ##need to do both #1 and #2 for this one too    published_year_month\n",
    "\n",
    "    try:#4\n",
    "        published_all=soup.find_all('div',attrs={'class':'row'})[1].get_text()\n",
    "        published_all=published_all.lower()\n",
    "        try:#3\n",
    "            #1\n",
    "            f_Published = soup.find('nobr',attrs={'class':'greyText'}).get_text()\n",
    "            f_Published=f_Published.lower()\n",
    "\n",
    "            first_published_year0= re.findall(\"\\d\\d\\d\\d\",f_Published)\n",
    "            if len(first_published_year0)==0:\n",
    "                first_published_year.append(np.nan)\n",
    "            else:\n",
    "                first_published_year.append(first_published_year0[0])\n",
    "\n",
    "            #2\n",
    "#           month_dict is up\n",
    "\n",
    "            xxx=0\n",
    "            for month in month_dict:\n",
    "                if (f_Published.find(month) != -1):\n",
    "                    xxx=month_dict.get(month)\n",
    "            if(xxx!=0):\n",
    "                first_published_month.append(xxx)\n",
    "            else:\n",
    "                first_published_month.append(np.nan)\n",
    "            \n",
    "        except:\n",
    "            first_published_year.append(np.nan)\n",
    "            first_published_month.append(np.nan)\n",
    "            f_Published=\"\"\n",
    "            ##x=\"\"###=f_Published##\n",
    "            \n",
    "            \n",
    "        published_year_month=published_all.replace(f_Published, \"\")\n",
    "        \n",
    "        published_year0= re.findall(\"\\d\\d\\d\\d\",published_year_month)\n",
    "        if len(published_year0)==0:\n",
    "            published_year.append(np.nan)\n",
    "        else:\n",
    "            published_year.append(published_year0[0])\n",
    "\n",
    "        #2\n",
    "#       month_dict is up\n",
    "        yyy=0\n",
    "        for month in month_dict:\n",
    "            if (published_year_month.find(month) != -1):\n",
    "                yyy=month_dict.get(month)\n",
    "        if(yyy!=0):\n",
    "            published_month.append(yyy)\n",
    "        else:\n",
    "            published_month.append(np.nan)\n",
    "            \n",
    "    except:\n",
    "        first_published_year.append(np.nan)\n",
    "        first_published_month.append(np.nan)\n",
    "\n",
    "        published_year.append(np.nan)\n",
    "        published_month.append(np.nan)\n",
    "\n",
    "######################################################################################################            \n",
    "        #get the rating for the current book    \n",
    "    try:    \n",
    "        so1 = driver.find_element(By.ID, \"rating_details\")\n",
    "        time.sleep(2)\n",
    "        so1.click()\n",
    "            \n",
    "            # get the html after simulating a button click\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        try:#1\n",
    "            rating_distribution = soup.find('table',attrs={'id':'rating_distribution'}).get_text()\n",
    "            rating_text = re.sub(r'[^0-9 ]', '', rating_distribution)\n",
    "            rating_text1 = rating_text.split()\n",
    "\n",
    "            Rating5.append(rating_text1[2])\n",
    "            Rating4.append(rating_text1[5])\n",
    "            Rating3.append(rating_text1[8])\n",
    "            Rating2.append(rating_text1[11])\n",
    "            Rating1.append(rating_text1[14])\n",
    "\n",
    "            Rating5_Percent.append(rating_text1[1])\n",
    "            Rating4_Percent.append(rating_text1[4])\n",
    "            Rating3_Percent.append(rating_text1[7])\n",
    "            Rating2_Percent.append(rating_text1[10])\n",
    "            Rating1_Percent.append(rating_text1[13])\n",
    "        except:\n",
    "            Rating5.append(np.nan)\n",
    "            Rating4.append(np.nan)\n",
    "            Rating3.append(np.nan)\n",
    "            Rating2.append(np.nan)\n",
    "            Rating1.append(np.nan)\n",
    "\n",
    "            Rating5_Percent.append(np.nan)\n",
    "            Rating4_Percent.append(np.nan)\n",
    "            Rating3_Percent.append(np.nan)\n",
    "            Rating2_Percent.append(np.nan)\n",
    "            Rating1_Percent.append(np.nan)\n",
    "        try:#2\n",
    "            people_liked0=soup.find('div',attrs={'id':'moreBookData'}).find('span').get_text()\n",
    "            people_liked.append(people_liked0)        \n",
    "\n",
    "        except:\n",
    "            people_liked.append(np.nan)\n",
    "    except:\n",
    "        Rating5.append(np.nan)\n",
    "        Rating4.append(np.nan)\n",
    "        Rating3.append(np.nan)\n",
    "        Rating2.append(np.nan)\n",
    "        Rating1.append(np.nan)\n",
    "\n",
    "        Rating5_Percent.append(np.nan)\n",
    "        Rating4_Percent.append(np.nan)\n",
    "        Rating3_Percent.append(np.nan)\n",
    "        Rating2_Percent.append(np.nan)\n",
    "        Rating1_Percent.append(np.nan)\n",
    "\n",
    "        people_liked.append(np.nan)\n",
    "        \n",
    "    df2= pd.DataFrame({'book_name':book_name,'book_series':book_series,'book_series_number':book_series_number,\n",
    "          'authorName':authorName,'description':description,'pages':pages,'rating':rating,'rating_Count':rating_Count,\n",
    "          'reviews_Count':reviews_Count,'ISBN':ISBN,'ISBN13':ISBN13,'published_year':published_year,\n",
    "          'published_month':published_month,'first_published_year':first_published_year,\n",
    "          'first_published_month':first_published_month,'Rating5':Rating5,'Rating4':Rating4,'Rating3':Rating3,\n",
    "          'Rating2':Rating2,'Rating1':Rating1,'Rating5_Percent':Rating5_Percent,'Rating4_Percent':Rating4_Percent,\n",
    "          'Rating3_Percent':Rating3_Percent,'Rating2_Percent':Rating2_Percent,'Rating1_Percent':Rating1_Percent,\n",
    "          'people_liked':people_liked})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513ab70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42f3f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.DataFrame({'book_name':book_name,'book_series':book_series,'book_series_number':book_series_number,\n",
    "                  'authorName':authorName,'description':description,'pages':pages,'rating':rating,'rating_Count':rating_Count,\n",
    "                  'reviews_Count':reviews_Count,'ISBN':ISBN,'ISBN13':ISBN13,'published_year':published_year,\n",
    "                  'published_month':published_month,'first_published_year':first_published_year,\n",
    "                  'first_published_month':first_published_month,'Rating5':Rating5,'Rating4':Rating4,'Rating3':Rating3,\n",
    "                  'Rating2':Rating2,'Rating1':Rating1,'Rating5_Percent':Rating5_Percent,'Rating4_Percent':Rating4_Percent,\n",
    "                  'Rating3_Percent':Rating3_Percent,'Rating2_Percent':Rating2_Percent,'Rating1_Percent':Rating1_Percent,\n",
    "                  'people_liked':people_liked})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90a71565",
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii=iiii+4000\n",
    "name=\"books_40_\"+str(iiii)+\".csv\"\n",
    "df2.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b4488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27f96b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4064 1\n",
      "4064 2\n",
      "4064 3\n",
      "4064 4\n",
      "4064 5\n",
      "4064 6\n",
      "4064 7\n",
      "4064 8\n",
      "4064 9\n",
      "4064 10\n",
      "4064 11\n",
      "4064 12\n",
      "4064 13\n",
      "4064 14\n",
      "4064 15\n",
      "4064 16\n",
      "4064 17\n",
      "4064 18\n",
      "4064 19\n",
      "4064 20\n",
      "4064 21\n",
      "4064 22\n",
      "4064 23\n",
      "4064 24\n",
      "4064 25\n",
      "4064 26\n"
     ]
    }
   ],
   "source": [
    "print(len(book_name),\"1\")\n",
    "print(len(book_series),\"2\")\n",
    "print(len(book_series_number),\"3\")\n",
    "print(len(authorName),\"4\")\n",
    "print(len(description),\"5\")\n",
    "print(len(pages),\"6\")\n",
    "\n",
    "\n",
    "print(len(rating),\"7\")\n",
    "print(len(rating_Count),\"8\")\n",
    "print(len(reviews_Count),\"9\")\n",
    "\n",
    "\n",
    "print(len(ISBN),\"10\")\n",
    "print(len(ISBN13),\"11\")\n",
    "\n",
    "\n",
    "\n",
    "print(len(published_year),\"12\")\n",
    "print(len(published_month),13)\n",
    "print(len(first_published_year),14)\n",
    "print(len(first_published_month),15)\n",
    "\n",
    "\n",
    "print(len(Rating5),16)\n",
    "print(len(Rating4),17)\n",
    "print(len(Rating3),18)\n",
    "print(len(Rating2),19)\n",
    "print(len(Rating1),20)\n",
    "\n",
    "print(len(Rating5_Percent),21)\n",
    "print(len(Rating4_Percent),22)\n",
    "print(len(Rating3_Percent),23)\n",
    "print(len(Rating2_Percent),24)\n",
    "print(len(Rating1_Percent),25)\n",
    "\n",
    "print(len(people_liked),26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04af7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
